% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ens_verify.R
\name{ens_verify}
\alias{ens_verify}
\alias{ens_verify.harp_ens_point_df}
\title{Compute all verification scores for an ensemble.}
\usage{
ens_verify(
  .fcst,
  parameter,
  verify_members = TRUE,
  thresholds = NULL,
  comparator = c("ge", "gt", "le", "lt", "eq", "between", "outside"),
  include_low = TRUE,
  include_high = TRUE,
  groupings = "lead_time",
  summary = TRUE,
  circle = NULL,
  rel_probs = NA,
  num_ref_members = NA,
  spread_drop_member = NULL,
  jitter_fcst = NULL,
  climatology = "sample",
  hexbin = TRUE,
  num_bins = 30,
  rank_hist = TRUE,
  crps = TRUE,
  crps_decomp = TRUE,
  tw_crps = TRUE,
  brier = TRUE,
  reliability = TRUE,
  roc = TRUE,
  econ_val = TRUE,
  show_progress = TRUE,
  new_ens_score = NULL,
  new_ens_prob_score = NULL,
  new_ens_score_opts = list(),
  ...
)

\method{ens_verify}{harp_ens_point_df}(
  .fcst,
  parameter,
  verify_members = TRUE,
  thresholds = NULL,
  comparator = c("ge", "gt", "le", "lt", "eq", "between", "outside"),
  include_low = TRUE,
  include_high = TRUE,
  groupings = "lead_time",
  summary = TRUE,
  circle = NULL,
  rel_probs = NA,
  num_ref_members = NA,
  spread_drop_member = NULL,
  jitter_fcst = NULL,
  climatology = "sample",
  hexbin = TRUE,
  num_bins = 30,
  rank_hist = TRUE,
  crps = TRUE,
  crps_decomp = TRUE,
  tw_crps = TRUE,
  brier = TRUE,
  reliability = TRUE,
  roc = TRUE,
  econ_val = TRUE,
  show_progress = TRUE,
  new_ens_score = NULL,
  new_ens_prob_score = NULL,
  new_ens_score_opts = list(),
  fcst_model = NULL,
  ...
)
}
\arguments{
\item{.fcst}{A \code{harp_df} or \code{harp_list} object with tables that have a column
for observations, or a single forecast table.}

\item{parameter}{The name of the column for the observations data. Can be the
column name, quoted, or unquoted. If a variable it should be embraced -
i.e. wrapped in \code{{{}}}.}

\item{verify_members}{Whether to verify the individual members of the
ensemble. Even if thresholds are supplied, only summary scores are
computed. If you wish to compute categorical scores, the separate
\link[harpPoint]{det_verify} function must be used.}

\item{thresholds}{A numeric vector of thresholds for which to compute the
threshold based scores. Set to NULL (the default) to only compute summary
scores.}

\item{groupings}{The groups for which to compute the scores. See
\link[dplyr]{group_by} for more information of how grouping works.}

\item{summary}{Logical. Whether to compute summary scores or not. Default is
\code{TRUE}.}

\item{circle}{If set the parameter is assumed to be cyclic for bias
calculations. Should be this distance around a circle in the units of the
parameter, so would typically have a value of 360 for degrees or \code{2 * pi}
for radians.}

\item{rel_probs}{Probabilities to use for reliability diagrams. Set to NA
(the default) to select automatically.}

\item{num_ref_members}{For "fair" scores, the score is scaled to be valid for
this number of ensemble members. Set to NA (the default) to not modify the
score.}

\item{spread_drop_member}{Which members to drop for the calculation of the
ensemble variance and standard deviation. For harp_fcst objects, this can
be a numeric scalar - in which case it is recycled for all forecast models;
a list or numeric vector of the same length as the harp_fcst object, or a
named list with the names corresponding to names in the harp_fcst object.}

\item{jitter_fcst}{A function to perturb the forecast values by. This is used
to account for observation error in the rank histogram. For other
statistics it is likely to make little difference since it is expected that
the observations will have a mean error of zero.}

\item{climatology}{The climatology to use for the Brier Skill Score. Can be
"sample" for the sample climatology (the default), a named list with
elements eps_model and member to use a member of an eps model in the
harp_fcst object for the climatology, or a data frame with columns for
threshold and climatology and also optionally lead_time.}

\item{hexbin}{Logical. Whether to compute hexbins for forecast, observation
pairs. Defaults to \code{TRUE}. See \link{bin_fcst_obs} for more details.}

\item{num_bins}{The number of bins into which to partition observations for
the hexbin computation.}

\item{rank_hist}{Logical. Whether to compute the rank histogram. Defaults to
\code{TRUE}. Note that the computation of the rank histogram can be slow if
there is a large number (> 1000) of groups.}

\item{crps}{Logical. Whether to compute the CRPS. Defaults to \code{TRUE}.}

\item{crps_decomp}{Logical. Whether to compute the decomposition of the CRPS
into potential and reliability components.}

\item{tw_crps}{Logical. Whether to compute the the threshold weighted CRPS.
Note that tw_crps cannot be computed for \code{comparator = "eq"} or
\code{comparator = "outside"}. Will be ignored if no thresholds are set.}

\item{brier}{Logical. Whether to compute the Brier score. Defaults to \code{TRUE}.
Will be ignored if no thresholds are set.}

\item{reliability}{Logical. Whether to compute the reliability. Defaults to
\code{TRUE}. Will be ignored if no thresholds are set.}

\item{roc}{Logical. Whether to compute the Relative Operating Characteristic
(ROC). Defaults to \code{TRUE}. Will be ignored if no thresholds are set.}

\item{econ_val}{Logical. Whether to compute the economic value. Defaults to
\code{TRUE}. Will be ignored if no thresholds are set.}

\item{show_progress}{Logical - whether to show progress bars. Defaults to
\code{TRUE}.}

\item{new_ens_score}{Character vector. Names of other
scores to be computed that are not part of this function. Requires a
\verb{compute_ens_<name>()} and optionally a \verb{prep_ens_<name>()} function. See
\strong{Adding your own scores}.}

\item{new_ens_prob_score}{Character vector. Names of functions to compute
scores from the observed and forecast probabilities. See
\strong{Adding your own scores}.}

\item{...}{Reserved for methods.}

\item{fcst_model}{The name of the forecast model to use in the \code{fcst_model}
column of the output. If the function is dispatched on a \code{harp_list}
object, the names of the \code{harp_list} are automatically used.}

\item{new_score_opts}{Named list of options for \code{new_ens_score} and
\code{new_ens_prob_score}.}
}
\value{
A list containing three data frames: \code{ens_summary_scores},
\code{ens_threshold_scores} and \code{det_summary_scores}.
}
\description{
Compute all verification scores for an ensemble.
}
\section{Adding your own scores}{


You can add functions to compute scores using the infrastructure of
\code{ens_verify()}. These can be for scores calculated from the raw ensemble,
or from probabilities based on the thresholds and comparator.
\subsection{Scores computed from the raw ensemble}{

The name of the score is specified in the \code{new_ens_score} argument and
\code{ens_verify()} will look for a function with the name \verb{compute_ens_<name>}
that will compute the score using \code{\link[dplyr]{summarize}} or
similar. It will optionally look for a function with the name
\verb{prep_ens_<name>} that will do some preparation of the data for each row
before aggregation into the score. This is best illustrated with a
(slightly contrived!) example:

Let's say we want to compute the mean bias weighted by latitude, and we call
the score "weighted_bias". We begin by writing a prep function, which has
to take the forecast data frame, the name of the forecast columns, the
name of the observation column and optionally a list of options as arguments.

\preformatted{
prep_ens_weighted_bias <- function(df, fc_col, obs_col, ...) {
  df <- dplyr::mutate(
    df,
    dplyr::across(
      dplyr::all_of(fc_col),
      ~(.x - .data[[obs_col]]) * abs(lat / 90)
     )
  )
  ens_stats(df, sd = FALSE)
}
}

The above function will have the weighted mean bias in the \code{ens_mean} column
created by the \code{\link[harpCore]{ens_stats()}} function.

For the computation of the score, we can use \code{\link[dplyr]{summarize}}
to compute the mean for each group. The compute function needs to take
grouped data frame, some details about the progress bar and optionally a list
of arguments.

\preformatted{
compute_ens_weighted_bias <- function(grouped_df, show_pb, pb_env, ...) {
  res <- dplyr::summarize(
    grouped_df,
    weighted_bias = sum(ens_mean) / sum(abs(lat / 90))
  )
  tick_progress(show_pb, pb_env)
  res
}
}

We can now run \code{ens_verify(data, obs_col, new_ens_score = "weighted_bias")}

We could also make it an option whether to weight by any column by modifying
\code{prep_ens_weighted_bias} and \code{compute_ens_weighted_bias} and adding the
option to \code{new_ens_score_opts}

\preformatted{
prep_ens_weighted_bias <- function(df, fc_col, obs_col, opts) {
  df <- dplyr::mutate(
    df,
    dplyr::across(
      dplyr::all_of(fc_col),
      ~(.x - .data[[obs_col]]) * abs(.data[[opts$weight_col]])
     )
  )
  ens_stats(df, sd = FALSE)
}
}

\preformatted{
compute_ens_weighted_bias <- function(grouped_df, show_pb, pb_env, opts) {
  res <- dplyr::summarize(
    grouped_df,
    weighted_bias = sum(ens_mean) / sum(abs(.data[[opts$weight_col]]))
  )
  tick_progress(show_pb, pb_env)
  res
}
}

And then running

\preformatted{
ens_verify(
  data,
  obs_col,
  new_ens_score = "weighted_bias",
  new_ens_score_opts = list(weight_col = "lon")
)
}
}

\subsection{Scores computed from probabilities}{

Computing scores from probabilities is much simpler, since \code{ens_verify()} has
already prepped the data and you have the forecast probability and the
observed (binary) probability. Here you need to write a function that takes
the observed probability, the forecast probability, some information about
the progress bar, and optionally some options for the function.

In this example we will compute some quantiles of the difference between
the forecast and observed probabilities.

\preformatted{
prob_diff_quant <- function(ob_prob, fc_prob, show_pb, pb_env, opts) {
  res <- quantile(fc_prob - ob_prob, probs = opts$quants)
  tick_progress(show_pb, pb_env)
  if (length(res) < 1) {
    return(res)
  }
  list(res) # we need to return a list if more than 1 value.
}
}

And now we can run:
\preformatted{
ens_verify(
  data,
  obs_col,
  thresholds         = c(0, 0.5),
  new_ens_prob_score = "prob_diff_quant",
  new_ens_score_opts = list(quants = c(0.9, 0.99, 0.995, 1))
)
}
}
}

